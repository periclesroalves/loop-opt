#!/usr/bin/python3
# This file is distributed under the Modified BSD Open Source License.
# See LICENSE.TXT for details.

## Reads the alias trace generated by an instrumented program run line by line
# and accumulates the alias and noalias counts for each loop and pair of variables.

import collections
import re
import argparse

DEFAULT_SHOULD_NOT_ALIAS_TRESHOLD   =   5
DEFAULT_SHOULD_ALIAS_EXACT_TRESHOLD = 100

parser = argparse.ArgumentParser(description='aggregate alias profiling data')
parser.add_argument(
	'trace_file',
	metavar='TRACE_FILE',
	type=str,
	help='Trace file with alias information')
parser.add_argument(
	'dst_file',
	metavar='DST_FILE',
	type=str,
	help='Output file')
parser.add_argument(
	'--should-not-alias-threshold',
	dest='should_not_alias_threshold',
	type=int,
	default=DEFAULT_SHOULD_NOT_ALIAS_TRESHOLD,
	help="A probability in percent, only pairs with a lower `malloc' alias probability are considered for cloning")
parser.add_argument(
	'--should-alias-exact-threshold',
	dest='should_alias_exact_threshold',
	type=int,
	default=DEFAULT_SHOULD_ALIAS_EXACT_TRESHOLD,
	help='A probability in percent, only pairs with a higher exact aliasing probability are considered for cloning')

args = parser.parse_args()

alias_trace_file = open(args.trace_file, "r")
dst_file         = open(args.dst_file,   "w")

def clamp(val, lo, hi):
	return max(min(val, hi), lo)

# proability threshold from which a pair of pointers is considered 'should-alias'
SHOULD_NOT_ALIAS_TRESHOLD   = clamp(float(args.should_not_alias_threshold)   / 100, 0, 1)
SHOULD_ALIAS_EXACT_TRESHOLD = clamp(float(args.should_alias_exact_threshold) / 100, 0, 1)

def TraceReader(file):
	## iterator that parses the trace file
	# each call to next() returns one alias pair data

	LINE_REGEX = re.compile("^CHECK '([\w.-]+)' - '([\w.-]+)' vs '([\w.-]+)' - ([\w]+) - (N|Y)$")

	line_no = 0

	for line in alias_trace_file:
		line_no += 1

		if not line:
			continue

		match = LINE_REGEX.match(line)

		if not match:
			raise Exception('Malformed entry on line ' + str(line_no))

		groups = match.groups()

		if not groups or len(groups) != 5:
			raise Exception('Malformed entry on line ' + str(line_no))

		fn, ptr1, ptr2, alias_type, yes_no = match.groups()

		yield (fn, ptr1, ptr2, alias_type, yes_no)

class Count:
	def __init__(self):
		self.yes = 0
		self.no  = 0

	@property
	def probability(self):
		total = self.yes + self.no

		if total:
			return self.yes / (self.yes + self.no)
		else:
			return 0

	def __str__(self):
		return type(self).__name__ + "(" + str(self.yes) + ", " + str(self.no) + ")"

## parse & aggregate data

data = {}

for fn_name, ptr1, ptr2, alias_type, yes_no in TraceReader(alias_trace_file):
	if fn_name not in data:
		data[fn_name] = {}

	fn   = data[fn_name]

	if ptr1 < ptr2:
		pair = (ptr1, ptr2)
	else:
		pair = (ptr2, ptr1)

	if pair not in fn:
		fn[pair] = {}

	counters = fn[pair]

	if alias_type not in counters:
		counters[alias_type] = Count()

	count = counters[alias_type]

	if yes_no == 'Y':
		count.yes += 1
	else:
		count.no  += 1

## print out yaml

def _print(*args):
	print(sep="", *args, file=dst_file)

for name, pairs in data.items():
	_print('---')
	_print('function: "', name, '"')
	_print('alias_pairs:')

	for pair, counters in pairs.items():
		_print(2*' ', '- ptr1: ', pair[0])
		_print(2*' ', '  ptr2: ', pair[1])

		for alias_type, count in counters.items():
			_print(2*' ', '  ', alias_type, ': ', count.probability)
	_print('...')
